{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranipriyanka20/hds5210-2023/blob/main/week15/week15_assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-fc1c39d0d6f8b82a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Zq0ZOFvliVvn"
      },
      "source": [
        "# Week 15 Programming Assignment\n",
        "\n",
        "The final thing for this semester that we haven't exercised, yet, is working with databases through Python.  In thi final assignment of the semester, you will practice pulling data from either Google Big Query or Snowflake, loading that data into a Pandas data frame, summarizing the data, and then exporting that to an Excel file.\n",
        "\n",
        "**You will need to use your own Google Big Query or Snowflake account to run this notebook, but you should try to make it configurable so anyone with an account in those technologies could run your notebook with minimal changes.**\n",
        "\n",
        "\n",
        "Build a notebook with good comments (either in code or in markdown cells).  Then submit your assignment as usual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRey-E1giVvq"
      },
      "source": [
        "### 1. Connect to the data source\n",
        "\n",
        "Follow the examples provided in the [week15 folder of our GitHub repository](https://github.com/paulboal/hds5210-2023/tree/main/week15) to connect your notebook either to Big Query or Snowflake."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"snowflake-connector-python[pandas]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tSHzqp7nxfB",
        "outputId": "c9217b2c-8b5a-4cad-eccc-d8a80ea09097"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snowflake-connector-python[pandas]\n",
            "  Downloading snowflake_connector_python-3.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asn1crypto<2.0.0,>0.24.0 (from snowflake-connector-python[pandas])\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi<2.0.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (1.16.0)\n",
            "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (41.0.7)\n",
            "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (23.3.0)\n",
            "Requirement already satisfied: pyjwt<3.0.0 in /usr/lib/python3/dist-packages (from snowflake-connector-python[pandas]) (2.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (2023.11.17)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (4.5.0)\n",
            "Requirement already satisfied: filelock<4,>=3.5 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (3.13.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (2.4.0)\n",
            "Collecting platformdirs<4.0.0,>=2.6.0 (from snowflake-connector-python[pandas])\n",
            "  Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
            "Collecting tomlkit (from snowflake-connector-python[pandas])\n",
            "  Downloading tomlkit-0.12.3-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pandas<2.2.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (1.5.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from snowflake-connector-python[pandas]) (9.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]) (2.21)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0.0->snowflake-connector-python[pandas]) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0.0->snowflake-connector-python[pandas]) (1.23.5)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->snowflake-connector-python[pandas]) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.2.0,>=1.0.0->snowflake-connector-python[pandas]) (1.16.0)\n",
            "Installing collected packages: asn1crypto, tomlkit, platformdirs, snowflake-connector-python\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.0.0\n",
            "    Uninstalling platformdirs-4.0.0:\n",
            "      Successfully uninstalled platformdirs-4.0.0\n",
            "Successfully installed asn1crypto-1.5.1 platformdirs-3.11.0 snowflake-connector-python-3.6.0 tomlkit-0.12.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x16SncD8iVvq"
      },
      "outputs": [],
      "source": [
        "import snowflake.connector\n",
        "\n",
        "# Check if `con` is defined and close it if it exists\n",
        "try:\n",
        "    con.close()\n",
        "except NameError:\n",
        "    pass  # `con` is not defined, so no need to close\n",
        "\n",
        "# Connect to Snowflake\n",
        "con = snowflake.connector.connect(\n",
        "    user='ranipriyankakatam',\n",
        "    password='Priyanka@2000',\n",
        "    account='ioaxejh-oh01162',\n",
        "    database='DEMO1',\n",
        "    schema='PUBLIC',\n",
        "    warehouse='COMPUTE_WH',\n",
        "    session_parameters={\n",
        "        'QUERY_TAG': 'Demo User Interaction',\n",
        "    }\n",
        ")\n",
        "\n",
        "# Now you can use the `con` connection for executing queries or other operations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL30vd6oiVvr"
      },
      "source": [
        "### 2. Query some data\n",
        "\n",
        "Assuming the source database has some data in it or that you can load some data into it from any source, query it.  Then, read that data into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qfehK6m8iVvr"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = con.cursor().execute('''  select * from IDENTIFIER('\"DEMO1\".\"PUBLIC\".\"WEEK15\"') limit 100;''').fetch_pandas_all()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihaGCARWiVvr"
      },
      "source": [
        "### 3. Aggregate your data frame\n",
        "\n",
        "Do some kind of aggregation on your data frame.  Something that makes sense and has some groups to it.  Don't just sum up one column for the entire data frame.  Be more creative than that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8uuPfC7QiVvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e18f176-446f-40b8-9622-93c43f80d0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated Data:\n",
            "    LEVEL        AGE  ALCOHOL_USE\n",
            "0    High  38.454545            8\n",
            "1     Low  35.677419            7\n",
            "2  Medium  38.388889            8\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# calculate the average age and maximum alcohol use\n",
        "aggregated_df = df.groupby('LEVEL').agg({'AGE': 'mean', 'ALCOHOL_USE': 'max'}).reset_index()\n",
        "\n",
        "# Print the aggregated DataFrame\n",
        "print(\"Aggregated Data:\")\n",
        "print(aggregated_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2-bjVWTiVvs"
      },
      "source": [
        "### 4. Write to Excel\n",
        "\n",
        "Use Pandas functions to write your summarized data out to a local Excel file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j2z2e_dmiVvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4f86c51-5b5e-450d-d3d9-98f0aeb256f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been successfully aggregated and written to output_file.xlsx.\n"
          ]
        }
      ],
      "source": [
        "# Write the aggregated data to an Excel file\n",
        "output_file_path = 'output_file.xlsx'\n",
        "aggregated_df.to_excel(output_file_path, index=False)\n",
        "\n",
        "print(f\"Data has been successfully aggregated and written to {output_file_path}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIgNoFrciVvs"
      },
      "source": [
        "---\n",
        "\n",
        "## Submitting Your Work\n",
        "\n",
        "Submit your work as usual"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}